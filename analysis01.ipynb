{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b286c55e-7ce1-4498-a103-d03497e543b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from keras.layers import Input\n",
    "from keras.applications import ResNet50\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23ae4b93-b193-4385-91bb-3932504a49c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load and preprocess NIfTI images\n",
    "def load_and_preprocess_nifti1(nifti_path, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Loads a NIfTI image, resizes it, and returns it as a NumPy array.\n",
    "\n",
    "    Parameters:\n",
    "    - nifti_path: Path to the NIfTI image file.\n",
    "    - target_size: Tuple specifying the target size (height, width) for resizing.\n",
    "\n",
    "    Returns:\n",
    "    - Resized image as a NumPy array.\n",
    "    \"\"\"\n",
    "    nifti_image = nib.load(nifti_path)\n",
    "    nifti_data = nifti_image.get_fdata()  # Get the image data as a NumPy array\n",
    "    # Assuming we are working with 2D slices, pick the middle slice along the z-axis\n",
    "    middle_slice = nifti_data[:, :, nifti_data.shape[2] // 2]\n",
    "    resized_img = tf.image.resize(middle_slice, target_size)\n",
    "    return np.array(resized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1821a8bf-8832-428d-966b-c723eb58cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load and preprocess NIfTI images\n",
    "def load_and_preprocess_nifti(nifti_path, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Loads a NIfTI image, resizes it, and returns it as a NumPy array.\n",
    "\n",
    "    Parameters:\n",
    "    - nifti_path: Path to the NIfTI image file.\n",
    "    - target_size: Tuple specifying the target size (height, width) for resizing.\n",
    "\n",
    "    Returns:\n",
    "    - Resized image as a NumPy array.\n",
    "    \"\"\"\n",
    "    nifti_image = nib.load(nifti_path)\n",
    "    nifti_data = nifti_image.get_fdata()  # Get the image data as a NumPy array\n",
    "    # Assuming we are working with 2D slices, pick the middle slice along the z-axis\n",
    "    middle_slice = nifti_data[:, :, nifti_data.shape[2] // 2]\n",
    "\n",
    "    # Add an extra dimension to make it a 3D tensor (H, W, 1) before resizing\n",
    "    middle_slice = np.expand_dims(middle_slice, axis=-1)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = tf.image.resize(middle_slice, target_size)\n",
    "\n",
    "    # Squeeze to remove the added dimension\n",
    "    return np.squeeze(resized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "936a87f1-574d-4ce8-b5ba-a81948c79786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_empty_image(nifti_path):\n",
    "    \"\"\"\n",
    "    Check if the NIfTI image is empty.\n",
    "\n",
    "    Parameters:\n",
    "    - nifti_path: Path to the NIfTI image file.\n",
    "\n",
    "    Returns:\n",
    "    - True if the image is empty, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nifti_image = nib.load(nifti_path)\n",
    "        return True\n",
    "    except ImageFileError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d253a14-1c4a-4d07-8337-1edd39f23343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage in loading function\n",
    "def load_and_stack_nifti(patient_folder, patient_folder_name, target_size=(224, 224)):\n",
    "    stacked_imgs = []\n",
    "    \n",
    "    # Define MRI file name suffixes\n",
    "    mri_suffixes = {\n",
    "        'T1': '-t1n.nii.gz',\n",
    "        'T1 CE': '-t1c.nii.gz',\n",
    "        'T2': '-t2w.nii.gz',\n",
    "        'T2 FLAIR': '-t2f.nii.gz'\n",
    "    }\n",
    "    \n",
    "    for mri_type, suffix in mri_suffixes.items():\n",
    "        nifti_image_path = os.path.join(patient_folder, f'{patient_folder_name}{suffix}')\n",
    "        if os.path.exists(nifti_image_path):\n",
    "            try:\n",
    "                img = load_and_preprocess_nifti(nifti_image_path, target_size)\n",
    "                stacked_imgs.append(img)\n",
    "            except Exception:\n",
    "                continue\n",
    "    \n",
    "    if len(stacked_imgs) < 4:\n",
    "        print(f\"Warning: No valid MRI images found for patient {patient_folder_name}.\")\n",
    "        return None  # Return None or handle as needed\n",
    "    \n",
    "    return np.stack(stacked_imgs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29b849fa-c668-4bb3-98f8-8dbd7eb7fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load and stack multiple NIfTI MRI images\n",
    "def load_and_stack_nifti1(patient_folder, patient_folder_name, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Loads and stacks NIfTI images for different MRI types as separate channels.\n",
    "\n",
    "    Parameters:\n",
    "    - patient_folder: Path to the folder containing patient's MRI scans.\n",
    "    - patient_folder_name: Name of the patient folder for constructing file names.\n",
    "    - target_size: Target size to resize the images (ignoring depth for 2D CNN).\n",
    "\n",
    "    Returns:\n",
    "    - Stacked image array where each MRI type is a separate channel.\n",
    "    \"\"\"\n",
    "    stacked_imgs = []\n",
    "    \n",
    "    # Define MRI file name suffixes\n",
    "    mri_suffixes = {\n",
    "        'T1': '-t1n.nii.gz',\n",
    "        'T1 CE': '-t1c.nii.gz',\n",
    "        'T2': '-t2w.nii.gz',\n",
    "        'T2 FLAIR': '-t2f.nii.gz'\n",
    "    }\n",
    "    \n",
    "    for mri_type, suffix in mri_suffixes.items():\n",
    "        nifti_image_path = os.path.join(patient_folder, f'{patient_folder_name}{suffix}')\n",
    "        if os.path.exists(nifti_image_path):\n",
    "            img = load_and_preprocess_nifti(nifti_image_path, target_size)\n",
    "            stacked_imgs.append(img)  # Append each image to the list of channels\n",
    "    \n",
    "    return np.stack(stacked_imgs, axis=-1)  # Stack along the channel axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1af048c2-a9ac-494a-8c84-4bc741b94e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load dataset with MRI stacking\n",
    "def load_dataset(dataset_path):\n",
    "    \"\"\"\n",
    "    Loads the dataset and stacks multiple MRI scans as channels.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset_path: Path to the dataset folder.\n",
    "\n",
    "    Returns:\n",
    "    - X: Array of stacked images.\n",
    "    - y: Array of labels (cancer levels).\n",
    "    \"\"\"\n",
    "    d = {\"51_OtherNeoplasms\":1, \"95_Glioma\":2}\n",
    "    X = []\n",
    "    y = []\n",
    "    cancer_levels = os.listdir(dataset_path)  # Cancer level directories (labels)\n",
    "    skipped_images = 0\n",
    "    \n",
    "    for cancer_level in cancer_levels:\n",
    "        patient_folders = os.listdir(os.path.join(dataset_path, cancer_level))\n",
    "        \n",
    "        for patient in patient_folders:\n",
    "            patient_folder = os.path.join(dataset_path, cancer_level, patient)\n",
    "            \n",
    "            # Load and stack the four MRI images: T1, T1 CE, T2, T2 FLAIR\n",
    "            stacked_img = load_and_stack_nifti(patient_folder, patient, target_size=(224, 224))\n",
    "            \n",
    "            if stacked_img is not None:\n",
    "                X.append(stacked_img)  # Add stacked image to the dataset\n",
    "                y.append(d[cancer_level])  # Store cancer level as label (convert to integer)\n",
    "            else:\n",
    "                skipped_images += 1  # Count skipped images\n",
    "\n",
    "    print(\"Skipped Images =\", skipped_images)\n",
    "    # Convert to numpy arrays only if X is not empty and all images are valid\n",
    "    if X:\n",
    "        return np.array(X), np.array(y)\n",
    "    else:\n",
    "        print(\"Warning: No valid MRI images found. Returning empty arrays.\")\n",
    "        return np.array([]), np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "00981269-48aa-4cf8-9ca4-ed831e8fdfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape=(224, 224, 4), num_classes=4):\n",
    "    \"\"\"\n",
    "    Builds the CNN model using a modified ResNet50 as the base model.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_shape: Tuple representing the shape of the input image.\n",
    "    - num_classes: Number of output classes.\n",
    "    \n",
    "    Returns:\n",
    "    - Compiled Keras model.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    inp = layers.Input((dshape[0], dshape[1], dshape[2], 1))\n",
    "x = Conv3D(32, kernel_size=3,padding=\"same\", use_bias=False)(inp)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Conv3D(32, kernel_size=3,padding=\"same\", use_bias=False)(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = MaxPool3D(pool_size=3, padding='same')(x)\n",
    "x = Dropout(0)(x)\n",
    "\n",
    "x = Conv3D(64, kernel_size=3,padding=\"same\")(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Conv3D(64, kernel_size=3,padding=\"same\")(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = MaxPool3D(pool_size=2, padding='same')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Conv3D(64, kernel_size=3,padding=\"same\")(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Conv3D(64, kernel_size=3,padding=\"same\")(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = MaxPool3D(pool_size=2, padding='same')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = layers.Dense(3,activation='softmax')(x) \n",
    "model = models.Model(inputs=inp, outputs=x)\n",
    "model.summary()\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    #model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c53380b5-f802-466d-8351-02224a4d950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the CNN model using ResNet50\n",
    "def build_model1(input_shape=(224, 224, 4), num_classes=4):\n",
    "    \"\"\"\n",
    "    Builds the CNN model using ResNet50 as the base model.\n",
    "\n",
    "    Parameters:\n",
    "    - input_shape: Shape of the input image (height, width, channels).\n",
    "    - num_classes: Number of output classes for classification.\n",
    "\n",
    "    Returns:\n",
    "    - Compiled Keras model.\n",
    "    \"\"\"\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Freeze the base model layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3ae1bbc6-10ac-4422-b086-2e9492e562ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to train and evaluate the model\n",
    "def main():\n",
    "    dataset_path = 'PKG - BraTS-Africa/BraTS-Africa'  # Replace with the path to your dataset\n",
    "    \n",
    "    # Load dataset\n",
    "    X, y = load_dataset(dataset_path)\n",
    "    \n",
    "    # Split dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model(input_shape=(224, 224, 4), num_classes=len(np.unique(y)))\n",
    "    \n",
    "    # Train the model\n",
    "    #model.fit(X_train, y_train, epochs=10, batch_size=16, validation_split=0.1)\n",
    "\n",
    "    #history = model.fit(X_train, y_train, epochs=10, batch_size=16, validation_split=0.1)\n",
    "    print(y_train)\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=16, validation_split=0.1, class_weight=class_weights)\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Compare predicted classes with actual classes\n",
    "    print(\"Predicted classes:\", predicted_classes)\n",
    "    print(\"Actual classes:\", y_test)\n",
    "        \n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    print(f'Test accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c692034-9cff-4bde-8710-a06a923fb569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No valid MRI images found for patient BraTS-SSA-00230-000.\n",
      "Skipped Images = 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[59], line 20\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m class_weights \u001b[38;5;241m=\u001b[39m class_weight\u001b[38;5;241m.\u001b[39mcompute_class_weight(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y_train), y\u001b[38;5;241m=\u001b[39my_train)\n\u001b[0;32m     19\u001b[0m class_weight_dict \u001b[38;5;241m=\u001b[39m {i: weight \u001b[38;5;28;01mfor\u001b[39;00m i, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(class_weights)}\n\u001b[1;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Plot training & validation accuracy values\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\data_adapter.py:1293\u001b[0m, in \u001b[0;36mDataHandler._configure_dataset_and_inferred_steps\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m x\n\u001b[0;32m   1292\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter\u001b[38;5;241m.\u001b[39mget_dataset()\n\u001b[1;32m-> 1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_weight:\n\u001b[0;32m   1294\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(_make_class_weight_map_fn(class_weight))\n\u001b[0;32m   1295\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer_steps(steps_per_epoch, dataset)\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0800d9b1-69db-4305-ba4e-6ba3dba316e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
